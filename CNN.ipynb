{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model using CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN mainly work on image data and apply 'convolutional' filters, Have many layers with different task in each, we use max-pooling to reduce image size by reducing parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic steps in this cell\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_epochs = 10\n",
    "batch_size = 120\n",
    "learning_rate = 3e-05\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), \n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# implement the model\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(10, 30, 5)\n",
    "        self.conv3 = nn.Conv2d(30, 50, 5)\n",
    "        self.fc1 = nn.Linear(50, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = x.view(-1, 50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "# create an instance of the model\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer : 3 input channels, 6 output channels, 5 kernel size\n",
    "        \n",
    "        images = images.to(device) \n",
    "        labels = labels.to(device) \n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optim\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1)%2000==0:\n",
    "            print(f'Epoch:{epoch+1}/{num_epochs}, step:{i+1}/{n_total_steps}, Loss:{loss.item():.4f}')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of network = 9.96%\n",
      "accuracy of plane:0.0%\n",
      "accuracy of car:0.0%\n",
      "accuracy of bird:0.0%\n",
      "accuracy of cat:0.0%\n",
      "accuracy of deer:0.0%\n",
      "accuracy of dog:0.0%\n",
      "accuracy of frog:0.0%\n",
      "accuracy of horse:0.0%\n",
      "accuracy of ship:0.0%\n",
      "accuracy of truck:99.6%\n"
     ]
    }
   ],
   "source": [
    "# Testing on data\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct=0\n",
    "    n_samples=0\n",
    "    n_class_correct= [0 for i in range(10)]\n",
    "    n_class_samples= [0 for i in range(10)]\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples+=labels.size(0)\n",
    "        n_correct+=(predicted==labels).sum().item()\n",
    "        \n",
    "        for i in range(min(batch_size, len(labels))):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            \n",
    "            if (pred == label):\n",
    "                n_class_correct[label]+=1\n",
    "            n_class_samples[label]+=1\n",
    "            \n",
    "    acc = 100*n_correct/n_samples\n",
    "    print(f'accuracy of network = {acc}%')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100*n_class_correct[i]/n_class_samples[i]\n",
    "        print(f'accuracy of {classes[i]}:{acc}%')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
